{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c8355e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefos/miniconda3/envs/env1/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/stefos/miniconda3/envs/env1/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu130\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # TextBiomarkerModel Training Example\n",
    "#\n",
    "# This notebook demonstrates how to train the `TextBiomarkerModel` using the `BiomarkerTrainer`.\n",
    "# We'll use dummy data for this example.\n",
    "\n",
    "# %%\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import logging # Added for trainer logging\n",
    "\n",
    "# Assuming 'biomarkers' is installed or on the python path\n",
    "from biomarkers.models.text import TextBiomarkerModel\n",
    "from biomarkers.core.base import BiomarkerConfig\n",
    "from biomarkers.training.trainer import BiomarkerTrainer # Assuming trainer is in biomarkers.training\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Configure logging (optional, but helpful for trainer)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb26a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Configuration\n",
    "#\n",
    "# Define the configuration for the model and training.\n",
    "\n",
    "# %%\n",
    "config_dict = {\n",
    "    # --- Base Model Keys ---\n",
    "    'modality': 'text',\n",
    "    'model_type': 'TextBiomarkerModel',\n",
    "    'hidden_dim': 128,\n",
    "    'num_diseases': 5, # Number of output classes\n",
    "    'dropout': 0.2,\n",
    "    'device': device,\n",
    "    # --- TextBiomarkerModel Specific Keys ---\n",
    "    'embedding_dim': 768,\n",
    "    'max_seq_length': 128,\n",
    "    'use_pretrained': False,\n",
    "    'biomarker_feature_dim': 50,\n",
    "    # --- Trainer Keys ---\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.01,\n",
    "    'gradient_clip': 1.0,\n",
    "    'epochs': 3, # Keep epochs low for a quick example\n",
    "    'batch_size': 8\n",
    "}\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Dummy Data and DataLoader\n",
    "#\n",
    "# Create a simple dummy dataset and dataloader. In a real application, you would use your `MultiModalBiomarkerDataset` and `create_dataloaders`.\n",
    "\n",
    "# %%\n",
    "class DummyTextDataset(Dataset):\n",
    "    def __init__(self, num_samples, seq_len, embedding_dim, num_classes):\n",
    "        self.num_samples = num_samples\n",
    "        self.seq_len = seq_len\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate random embeddings\n",
    "        # The trainer will move these to the correct device\n",
    "        embeddings = torch.randn(self.seq_len, self.embedding_dim)\n",
    "        # Generate a random target class\n",
    "        target = torch.randint(0, self.num_classes, (1,)).squeeze()\n",
    "\n",
    "        # Minimal batch structure expected by trainer\n",
    "        # Note: We are only providing 'input' and 'target'\n",
    "        # If your model *requires* metadata even during training loss calculation,\n",
    "        # you'll need to adapt this dummy dataset or the model.\n",
    "        # The current TextBiomarkerModel forward pass uses metadata for biomarker extraction,\n",
    "        # but the core classification loss only depends on 'logits' and 'target'.\n",
    "        return {'input': embeddings, 'target': target}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca1b5a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dummy train DataLoader with 13 batches.\n",
      "Created dummy validation DataLoader with 3 batches.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dataset parameters\n",
    "num_train_samples = 100\n",
    "num_val_samples = 20\n",
    "seq_len = config_dict['max_seq_length']\n",
    "embedding_dim = config_dict['embedding_dim']\n",
    "num_classes = config_dict['num_diseases']\n",
    "\n",
    "# Create Datasets\n",
    "train_dataset = DummyTextDataset(num_train_samples, seq_len, embedding_dim, num_classes)\n",
    "val_dataset = DummyTextDataset(num_val_samples, seq_len, embedding_dim, num_classes)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config_dict['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=0 # Set num_workers > 0 for actual data loading\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config_dict['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Created dummy train DataLoader with {len(train_loader)} batches.\")\n",
    "print(f\"Created dummy validation DataLoader with {len(val_loader)} batches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f97b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully!\n",
      "Model placed on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Model Initialization\n",
    "#\n",
    "# Instantiate the `TextBiomarkerModel`.\n",
    "\n",
    "# %%\n",
    "try:\n",
    "    model = TextBiomarkerModel(config_dict)\n",
    "    print(\"Model initialized successfully!\")\n",
    "    print(f\"Model placed on device: {next(model.parameters()).device}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error initializing model: {e}\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12aabfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Trainer Initialization\n",
    "#\n",
    "# Instantiate the `BiomarkerTrainer`. We'll disable `wandb` logging for this simple example.\n",
    "\n",
    "# %%\n",
    "try:\n",
    "    trainer = BiomarkerTrainer(\n",
    "        model=model,\n",
    "        config=config_dict,\n",
    "        use_wandb=False # Disable wandb for this local example\n",
    "    )\n",
    "    print(\"Trainer initialized successfully!\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error initializing trainer: {e}\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4d3939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for 3 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 13/13 [00:00<00:00, 21.91it/s, loss=1.62, acc=0.183]\n",
      "Evaluating: 100%|██████████| 3/3 [00:00<00:00, 80.92it/s]\n",
      "/home/stefos/miniconda3/envs/env1/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0/3\n",
      "Train Loss: 1.6191, Train Acc: 0.1827\n",
      "Val Acc: 0.2500, Val F1: 0.0800\n",
      "Saved best model with F1 score: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 13/13 [00:00<00:00, 38.38it/s, loss=1.57, acc=0.163]\n",
      "Evaluating: 100%|██████████| 3/3 [00:00<00:00, 89.21it/s]\n",
      "/home/stefos/miniconda3/envs/env1/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "Train Loss: 1.6038, Train Acc: 0.1635\n",
      "Val Acc: 0.2000, Val F1: 0.0667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 13/13 [00:00<00:00, 38.31it/s, loss=1.64, acc=0.154]\n",
      "Evaluating: 100%|██████████| 3/3 [00:00<00:00, 88.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/3\n",
      "Train Loss: 1.6157, Train Acc: 0.1538\n",
      "Val Acc: 0.1000, Val F1: 0.0364\n",
      "\n",
      "Training finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/stefos/miniconda3/envs/env1/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Training Loop\n",
    "#\n",
    "# Run the training using the `trainer.fit()` method.\n",
    "\n",
    "# %%\n",
    "num_epochs = config_dict['epochs']\n",
    "save_directory = \"./biomarker_training_output\"\n",
    "\n",
    "print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
    "\n",
    "try:\n",
    "    trainer.fit(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=num_epochs,\n",
    "        save_dir=save_directory\n",
    "    )\n",
    "    print(\"\\nTraining finished!\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during training: {e}\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4e0d498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading best model from: biomarker_training_output/best_model.pt\n",
      "Best model loaded successfully.\n",
      "Model was saved at epoch 0\n",
      "Validation metrics at save: {'accuracy': 0.25, 'precision': 0.05, 'recall': 0.2, 'f1_score': 0.08, 'auc': 0.3823249299719888, 'disease_0_sensitivity': 0.0, 'disease_0_specificity': 1.0, 'disease_0_ppv': 0, 'disease_0_npv': 0.7, 'disease_1_sensitivity': 1.0, 'disease_1_specificity': 0.0, 'disease_1_ppv': 0.25, 'disease_1_npv': 0, 'disease_2_sensitivity': 0.0, 'disease_2_specificity': 1.0, 'disease_2_ppv': 0, 'disease_2_npv': 0.85, 'disease_3_sensitivity': 0.0, 'disease_3_specificity': 1.0, 'disease_3_ppv': 0, 'disease_3_npv': 0.75, 'disease_4_sensitivity': 0.0, 'disease_4_specificity': 1.0, 'disease_4_ppv': 0, 'disease_4_npv': 0.95, 'mean_uncertainty': 0.9767093658447266}\n",
      "\n",
      "Evaluating loaded model on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3/3 [00:00<00:00, 79.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "{\n",
      "  \"accuracy\": 0.3,\n",
      "  \"precision\": 0.06,\n",
      "  \"recall\": 0.2,\n",
      "  \"f1_score\": 0.09230769230769231,\n",
      "  \"auc\": 0.46050420168067224,\n",
      "  \"mean_uncertainty\": 0.9760211706161499\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/stefos/miniconda3/envs/env1/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Post-Training (Optional)\n",
    "#\n",
    "# After training, you can load the best model saved by the trainer and perform evaluation or inference.\n",
    "\n",
    "# %%\n",
    "best_model_path = Path(save_directory) / 'best_model.pt'\n",
    "\n",
    "if best_model_path.exists():\n",
    "    print(f\"\\nLoading best model from: {best_model_path}\")\n",
    "    try:\n",
    "        # Load checkpoint (contains model state, config, etc.)\n",
    "        checkpoint = torch.load(best_model_path, map_location=device)\n",
    "\n",
    "        # Re-initialize model with saved config\n",
    "        loaded_model_config = checkpoint['config']\n",
    "        loaded_model = TextBiomarkerModel(loaded_model_config)\n",
    "\n",
    "        # Load state dict\n",
    "        loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        loaded_model.eval() # Set to evaluation mode\n",
    "\n",
    "        print(\"Best model loaded successfully.\")\n",
    "        print(f\"Model was saved at epoch {checkpoint.get('epoch', 'N/A')}\")\n",
    "        print(f\"Validation metrics at save: {checkpoint.get('metrics', {})}\")\n",
    "\n",
    "        # Example: Evaluate the loaded model on the validation set\n",
    "        print(\"\\nEvaluating loaded model on validation set...\")\n",
    "        # Need a new trainer instance for evaluation if desired, or call evaluate directly\n",
    "        eval_trainer = BiomarkerTrainer(loaded_model, loaded_model_config, use_wandb=False)\n",
    "        final_val_metrics = eval_trainer.evaluate(val_loader, clinical_metrics=False) # Disable clinical for dummy data\n",
    "        print(\"Evaluation results:\")\n",
    "        print(json.dumps(final_val_metrics, indent=2))\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading or evaluating best model: {e}\")\n",
    "else:\n",
    "    print(f\"\\nBest model checkpoint not found at {best_model_path}. Training might have failed or not saved.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ---\n",
    "# End of Training Example\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619596db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
